{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64af477f",
   "metadata": {},
   "source": [
    "# Geospatial Data Processing Pipeline\n",
    "\n",
    "## Key Features\n",
    "- **Overture Maps download** via DuckDB with bounding box filtering\n",
    "- **Multi-format conversion** (Shapefile, GeoPackage, etc.) to GeoJSON\n",
    "- **Automated PMTiles generation** with tippecanoe settings per geometry type and/or theme\n",
    "\n",
    "## Processing Steps\n",
    "1. **Download** - Fetch Overture Maps data for specified extent\n",
    "2. **Convert** - Transform custom spatial data to GeoJSON format\n",
    "3. **Tile** - Generate PMTiles using tippecanoe with custom settings\n",
    "\n",
    "## Prerequisites\n",
    "- Python with required packages (duckdb, tqdm, pathlib)\n",
    "- Tippecanoe installed and available in PATH\n",
    "- GDAL/OGR for geospatial format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the three modular processing scripts\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Add the processing directory to Python path\n",
    "processing_dir = Path(\"./processing\")\n",
    "if str(processing_dir) not in sys.path:\n",
    "    sys.path.append(str(processing_dir))\n",
    "\n",
    "# Import modular processing scripts\n",
    "try:\n",
    "    from downloadOverture import download_overture_data\n",
    "    from convertCustomData import convert_file\n",
    "    from runCreateTiles import process_to_tiles, create_tilejson\n",
    "    print(\"Successfully imported all processing modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the processing scripts are in the ./processing directory\")\n",
    "\n",
    "# Import additional libraries for visualization and analysis\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008eff0",
   "metadata": {},
   "source": [
    "## 1. Project Configuration and Paths\n",
    "\n",
    "Configure the project directories and processing parameters for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09545d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - All paths and parameters centralized\n",
    "from pathlib import Path\n",
    "\n",
    "# Define all project paths\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "PROCESSING_DIR = PROJECT_ROOT / \"processing\"\n",
    "DATA_DIR = PROCESSING_DIR / \"data\"\n",
    "OVERTURE_DATA_DIR = DATA_DIR / \"raw\" / \"overture\"\n",
    "CUSTOM_DATA_DIR = DATA_DIR / \"raw\" / \"grid3\"\n",
    "OUTPUT_DIR = DATA_DIR / \"processed\"\n",
    "TILE_DIR = DATA_DIR / \"tiles\"\n",
    "PUBLIC_TILES_DIR = PROJECT_ROOT / \"public\" / \"tiles\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"paths\": {\n",
    "        \"project_root\": PROJECT_ROOT,\n",
    "        \"processing_dir\": PROCESSING_DIR,\n",
    "        \"data_dir\": DATA_DIR,\n",
    "        \"overture_data_dir\": OVERTURE_DATA_DIR,\n",
    "        \"custom_data_dir\": CUSTOM_DATA_DIR,\n",
    "        \"tile_dir\": TILE_DIR,\n",
    "        \"output_dir\" : OUTPUT_DIR,\n",
    "        \"public_tiles_dir\": PUBLIC_TILES_DIR,\n",
    "        \"template_path\": PROCESSING_DIR / \"tileQueries.template\"\n",
    "    },\n",
    "    \"extent\": {\n",
    "        # \"coordinates\": (22.0, -6.0, 24.0, -4.0),  # kasai-oriental\n",
    "        # Bounding box around Prospect Park points with a 0.01° buffer (~1.1 km)\n",
    "        # Points: (40.682140, -73.985371) and (40.6473912366065, -73.95500872565238)\n",
    "        \"coordinates\": (\n",
    "            -73.98257744202017,  # lon_min (clamped to Brooklyn bounds)\n",
    "            40.64773925613089,   # lat_min (clamped to Brooklyn bounds)\n",
    "            -73.9562859766083,   # lon_max (clamped to Brooklyn bounds)\n",
    "            40.67679734614368    # lat_max (clamped to Brooklyn bounds)\n",
    "        ),\n",
    "        \"buffer_degrees\": 0.0\n",
    "    },\n",
    "    \"download\": {\n",
    "        \"verbose\": True,\n",
    "        \"output_formats\": [\"*.geojson\", \"*.geojsonseq\"]\n",
    "    },\n",
    "    \"conversion\": {\n",
    "        \"input_patterns\": [\"*.shp\", \"*.gpkg\", \"*.gdb\", \"*.sqlite\", \"*.db\", \"*.geojson\", \"*.json\"],\n",
    "        \"output_suffix\": \".geojsonseq\",\n",
    "        \"reproject_crs\": \"EPSG:4326\",\n",
    "        \"overwrite\": True,\n",
    "        \"verbose\": True\n",
    "    },\n",
    "    \"tiling\": {\n",
    "        # \"input_dirs\": [CUSTOM_DATA_DIR, OVERTURE_DATA_DIR],  # Search in both data directories\n",
    "        \"input_dirs\": [OVERTURE_DATA_DIR],  # just overture\n",
    "        \"output_dir\": TILE_DIR,  # Explicit output directory for PMTiles\n",
    "        \"parallel\": True,\n",
    "        \"overwrite\": True,\n",
    "        \"verbose\": True,\n",
    "        \"create_tilejson\": True,\n",
    "        \"filter_pattern\": None  # Optional: filter files by pattern\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create necessary directories\n",
    "for path_key, path_value in CONFIG[\"paths\"].items():\n",
    "    if path_key.endswith(\"_dir\") and path_value:\n",
    "        path_value.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"PROJECT CONFIGURATION INITIALIZED\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Project root: {CONFIG['paths']['project_root']}\")\n",
    "print(f\"Processing directory: {CONFIG['paths']['processing_dir']}\")\n",
    "print(f\"Data directory: {CONFIG['paths']['data_dir']}\")\n",
    "print(f\"Output directory: {CONFIG['paths']['output_dir']}\")\n",
    "print(f\"Overture data directory: {CONFIG['paths']['overture_data_dir']}\")\n",
    "print(f\"Custom data directory: {CONFIG['paths']['custom_data_dir']}\")\n",
    "print(f\"Tile output directory: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"Public tiles directory: {CONFIG['paths']['public_tiles_dir']}\")\n",
    "print()\n",
    "print(f\"Processing extent: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"Buffer degrees: {CONFIG['extent']['buffer_degrees']}\")\n",
    "print(f\"Area: {(CONFIG['extent']['coordinates'][2] - CONFIG['extent']['coordinates'][0]) * (CONFIG['extent']['coordinates'][3] - CONFIG['extent']['coordinates'][1]):.2f} degree²\")\n",
    "print()\n",
    "print(\"All directories created and configuration loaded\")\n",
    "print(\"All modular functions will use CONFIG parameters instead of hardcoded defaults\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea97440",
   "metadata": {},
   "source": [
    "## 2. Download Overture Data with DuckDB\n",
    "\n",
    "Use the `downloadOverture.py` module to fetch geospatial data from Overture Maps. This module uses DuckDB to efficiently query and download data for specific geographic extents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b170545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Overture Maps data\n",
    "print(\"=== STEP 1: DOWNLOADING OVERTURE DATA ===\")\n",
    "download_results = download_overture_data(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    buffer_degrees=CONFIG[\"extent\"][\"buffer_degrees\"],\n",
    "    template_path=str(CONFIG[\"paths\"][\"template_path\"]),\n",
    "    verbose=CONFIG[\"download\"][\"verbose\"],\n",
    "    project_root=str(CONFIG[\"paths\"][\"project_root\"]),\n",
    "    overture_data_dir=str(CONFIG[\"paths\"][\"overture_data_dir\"])\n",
    ")\n",
    "\n",
    "print(f\"Download completed: {download_results['success']}\")\n",
    "print(f\"Sections processed: {download_results['processed_sections']}\")\n",
    "if download_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(download_results['errors'])}\")\n",
    "    for error in download_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f11f7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files were created during download\n",
    "print(\"=== CHECKING DOWNLOADED FILES ===\")\n",
    "\n",
    "overture_files = []\n",
    "search_dirs = [CONFIG[\"paths\"][\"data_dir\"], CONFIG[\"paths\"][\"overture_data_dir\"]]\n",
    "\n",
    "for data_dir in search_dirs:\n",
    "    if data_dir.exists():\n",
    "        for pattern in CONFIG[\"download\"][\"output_formats\"]:\n",
    "            files = list(data_dir.glob(pattern))\n",
    "            overture_files.extend(files)\n",
    "\n",
    "print(f\"Found {len(overture_files)} downloaded files:\")\n",
    "for file in sorted(overture_files):\n",
    "    file_size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "    print(f\"  {file.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Display file statistics\n",
    "if overture_files:\n",
    "    total_size_mb = sum(f.stat().st_size for f in overture_files) / 1024 / 1024\n",
    "    print(f\"\\nTotal size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Search directories: {[str(d) for d in search_dirs]}\")\n",
    "else:\n",
    "    print(\"No files found. Check download results above.\")\n",
    "    print(f\"Searched in: {[str(d) for d in search_dirs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacbe99",
   "metadata": {},
   "source": [
    "## 3. Convert Custom Spatial Data for Tippecanoe\n",
    "\n",
    "Use the `convertCustomData.py` module to convert various geospatial formats to newline-delimited GeoJSON files suitable for Tippecanoe \n",
    "\n",
    "### Supported Input Formats\n",
    "- Shapefile (.shp)\n",
    "- GeoPackage (.gpkg)\n",
    "- FileGDB (.gdb)\n",
    "- SQLite/SpatiaLite (.sqlite, .db)\n",
    "- PostGIS (connection string)\n",
    "- CSV with geometry columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for custom data files to convert\n",
    "print(\"=== STEP 3: CONVERTING CUSTOM SPATIAL DATA ===\")\n",
    "\n",
    "custom_input_dir = CONFIG[\"paths\"][\"custom_data_dir\"]\n",
    "custom_files = []\n",
    "\n",
    "# Search for various spatial data formats using CONFIG patterns\n",
    "for pattern in CONFIG[\"conversion\"][\"input_patterns\"]:\n",
    "    custom_files.extend(custom_input_dir.glob(pattern))\n",
    "\n",
    "print(f\"Found {len(custom_files)} custom data files to convert:\")\n",
    "print(f\"Search directory: {custom_input_dir}\")\n",
    "for file in custom_files:\n",
    "    print(f\"  {file.name}\")\n",
    "\n",
    "# Convert custom data files (if any exist)\n",
    "converted_files = []\n",
    "\n",
    "for input_file in custom_files:\n",
    "    output_file = CONFIG[\"paths\"][\"output_dir\"] / f\"{input_file.stem}{CONFIG['conversion']['output_suffix']}\"\n",
    "    \n",
    "    print(f\"Converting {input_file.name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Convert using the modular function with CONFIG settings\n",
    "        processed, skipped, output_path = convert_file(\n",
    "            input_path=str(input_file),\n",
    "            output_path=str(output_file),\n",
    "            reproject=CONFIG[\"conversion\"][\"reproject_crs\"],\n",
    "            verbose=CONFIG[\"conversion\"][\"verbose\"]\n",
    "        )\n",
    "        \n",
    "        converted_files.append(output_file)\n",
    "        print(f\"✓ Converted: {processed} features, {skipped} skipped\")\n",
    "        print(f\"  Output: {output_file.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error converting {input_file.name}: {e}\")\n",
    "\n",
    "if converted_files:\n",
    "    print(f\"\\n✓ Successfully converted {len(converted_files)} files\")\n",
    "    print(f\"  Output directory: {CONFIG['paths']['output_dir']}\")\n",
    "else:\n",
    "    print(f\"\\nNo custom files to convert. Add data files to: {custom_input_dir}\")\n",
    "    print(f\"Supported formats: {', '.join(CONFIG['conversion']['input_patterns'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a45ef5",
   "metadata": {},
   "source": [
    "## 3 1/2. Define tippecanoe parameters per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a0d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60968d93",
   "metadata": {},
   "source": [
    "## 4. Process GeoJSON/GeoJSONSeq to PMTiles\n",
    "\n",
    "Use the `runCreateTiles.py` module to convert GeoJSON and GeoJSONSeq files to PMTiles using optimized Tippecanoe settings.\n",
    "\n",
    "### Automatic Optimization Features\n",
    "- **Geometry Detection**: Automatically detects Point, LineString, or Polygon geometries\n",
    "- **Layer-Specific Settings**: Optimized settings for water, roads, places, land use, etc.\n",
    "- **Parallel Processing**: Multi-threaded processing for large datasets\n",
    "- **Quality Optimization**: Smart simplification and feature dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a575ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Process all GeoJSON/GeoJSONSeq files to PMTiles\n",
    "print(\"=== STEP 4: PROCESSING TO PMTILES ===\")\n",
    "\n",
    "# Process all downloaded and converted files to PMTiles using CONFIG settings\n",
    "tiling_results = process_to_tiles(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    input_dirs=[str(d) for d in CONFIG[\"tiling\"][\"input_dirs\"]],  # Convert Path objects to strings\n",
    "    filter_pattern=CONFIG[\"tiling\"][\"filter_pattern\"],  # Pass filter pattern from CONFIG\n",
    "    output_dir=str(CONFIG[\"tiling\"][\"output_dir\"]),  # Use explicit output directory from CONFIG\n",
    "    parallel=CONFIG[\"tiling\"][\"parallel\"],\n",
    "    verbose=CONFIG[\"tiling\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "print(f\"Tiling completed: {tiling_results['success']}\")\n",
    "print(f\"Files processed: {len(tiling_results['processed_files'])}/{tiling_results['total_files']}\")\n",
    "\n",
    "if tiling_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(tiling_results['errors'])}\")\n",
    "    for error in tiling_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Display generated PMTiles files\n",
    "if tiling_results[\"processed_files\"]:\n",
    "    print(f\"\\n✓ Successfully generated {len(tiling_results['processed_files'])} PMTiles:\")\n",
    "    \n",
    "    pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "    \n",
    "    total_size_mb = 0\n",
    "    for pmtile in sorted(pmtiles_files):\n",
    "        size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "        total_size_mb += size_mb\n",
    "        print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Files location: {CONFIG['paths']['tile_dir']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo PMTiles files were generated. Check the errors above.\")\n",
    "    print(f\"Make sure you have GeoJSON/GeoJSONSeq files in: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f46e1",
   "metadata": {},
   "source": [
    "## 5. Create TileJSON Metadata\n",
    "\n",
    "Generate TileJSON metadata files for seamless integration with web mapping libraries like MapLibre GL JS.\n",
    "\n",
    "### TileJSON Features\n",
    "- **Bounds and zoom levels** automatically detected from PMTiles\n",
    "- **Vector layer definitions** for each data layer\n",
    "- **MapLibre GL JS compatibility** for easy web integration\n",
    "- **PMTiles URL references** for efficient tile serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57093621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create TileJSON metadata for MapLibre integration\n",
    "print(\"=== STEP 5: CREATING TILEJSON METADATA ===\")\n",
    "\n",
    "# Check if PMTiles files exist in the configured tile directory\n",
    "pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "\n",
    "if pmtiles_files:\n",
    "    print(f\"Found {len(pmtiles_files)} PMTiles files, creating TileJSON...\")\n",
    "    \n",
    "    try:\n",
    "        tilejson = create_tilejson(\n",
    "            tile_dir=str(CONFIG[\"paths\"][\"tile_dir\"]),  # Explicitly pass tile directory\n",
    "            extent=CONFIG[\"extent\"][\"coordinates\"],  # Pass extent from CONFIG\n",
    "            output_file=str(CONFIG[\"paths\"][\"tile_dir\"] / \"tilejson.json\")  # Explicitly pass output file path\n",
    "        )\n",
    "        \n",
    "        print(\"✓ TileJSON created successfully\")\n",
    "        print(f\"  Bounds: {tilejson['bounds']}\")\n",
    "        print(f\"  Zoom range: {tilejson['minzoom']} - {tilejson['maxzoom']}\")\n",
    "        print(f\"  Vector layers: {len(tilejson['vector_layers'])}\")\n",
    "        print(f\"  Output file: {CONFIG['paths']['tile_dir'] / 'tilejson.json'}\")\n",
    "        \n",
    "        # Show a summary of all output files\n",
    "        print(f\"\\nComplete output summary:\")\n",
    "        total_size_mb = 0\n",
    "        for pmtile in sorted(pmtiles_files):\n",
    "            size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "            total_size_mb += size_mb\n",
    "            print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        print(f\"  tilejson.json\")\n",
    "        print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "        print(f\"All files location: {CONFIG['paths']['tile_dir']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ TileJSON creation failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No PMTiles files found in output directory.\")\n",
    "    print(f\"Expected location: {CONFIG['paths']['tile_dir']}\")\n",
    "    print(\"Run Step 4 first to generate PMTiles files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755057e5",
   "metadata": {},
   "source": [
    "## 6. Validate and Test Individual Steps\n",
    "\n",
    "Test each processing step individually and validate the generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Step Testing and Validation\n",
    "\n",
    "print(\"INDIVIDUAL STEP TESTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. Test downloadOverture.py standalone:\")\n",
    "print(\"python processing/downloadOverture.py --extent='23.4,-6.2,23.8,-5.8' --buffer=0.1\")\n",
    "\n",
    "print(\"\\n2. Test convertCustomData.py standalone:\")\n",
    "print(\"python processing/convertCustomData.py input.shp output.geojsonseq --reproject=EPSG:4326\")\n",
    "\n",
    "print(\"\\n3. Test runCreateTiles.py standalone:\")\n",
    "print(\"python processing/runCreateTiles.py --extent='23.4,-6.2,23.8,-5.8' --create-tilejson\")\n",
    "\n",
    "print(\"\\n4. Test individual steps in this notebook:\")\n",
    "print(\"   - Step 1: Download section (cell 6)\")\n",
    "print(\"   - Step 2: Check downloaded files (cell 7)\")\n",
    "print(\"   - Step 3: Convert custom data (cell 9)\")\n",
    "print(\"   - Step 4: Process to PMTiles (cell 11)\")\n",
    "print(\"   - Step 5: Create TileJSON (cell 13)\")\n",
    "\n",
    "print(\"\\n5. Validate outputs using CONFIG paths:\")\n",
    "print(f\"   - Check {CONFIG['paths']['data_dir']} for GeoJSON files\")\n",
    "print(f\"   - Check {CONFIG['paths']['tile_dir']} for PMTiles files\")\n",
    "print(f\"   - Verify TileJSON metadata file\")\n",
    "\n",
    "# Configuration validation using centralized CONFIG\n",
    "print(\"\\nCURRENT CONFIGURATION VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Extent: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"Buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "print(f\"Tile output directory: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"Custom data directory: {CONFIG['paths']['custom_data_dir']}\")\n",
    "print(f\"Input directories for tiling: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")\n",
    "\n",
    "# Area calculation using CONFIG\n",
    "extent = CONFIG['extent']['coordinates']\n",
    "area = (extent[2] - extent[0]) * (extent[3] - extent[1])\n",
    "print(f\"Processing area: {area:.2f} degree² ({area * 111**2:.0f} km²)\")\n",
    "\n",
    "# Check directory status\n",
    "print(f\"\\nDIRECTORY STATUS\")\n",
    "print(\"=\" * 30)\n",
    "for path_name, path_obj in CONFIG['paths'].items():\n",
    "    if path_name.endswith('_dir'):\n",
    "        status = \"exists\" if path_obj.exists() else \"missing\"\n",
    "        file_count = len(list(path_obj.glob(\"*\"))) if path_obj.exists() else 0\n",
    "        print(f\"{path_name}: {status} ({file_count} files)\")\n",
    "\n",
    "print(\"\\nPERFORMANCE OPTIMIZATION TIPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. For large areas (current: {area:.2f} degree²):\")\n",
    "print(f\"   - Current buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "print(f\"   - Parallel processing: {CONFIG['tiling']['parallel']}\")\n",
    "print(\"   - Consider smaller chunks if memory issues occur\")\n",
    "\n",
    "print(\"\\n2. File management:\")\n",
    "print(f\"   - Monitor {CONFIG['paths']['data_dir']} size during processing\")\n",
    "print(\"   - Clean intermediate files between steps if needed\")\n",
    "print(\"   - Use filter patterns to process specific layers only\")\n",
    "\n",
    "print(\"\\n3. Output optimization:\")\n",
    "print(f\"   - PMTiles output: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"   - Public tiles: {CONFIG['paths']['public_tiles_dir']}\")\n",
    "print(\"   - Copy final tiles to public directory for web serving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ee77b",
   "metadata": {},
   "source": [
    "# Modular Processing Summary\n",
    "\n",
    "This notebook provides a complete, step-by-step approach for geospatial data processing with the following capabilities:\n",
    "\n",
    "## Core Steps\n",
    "1. **Download Overture Maps data** with spatial filtering using DuckDB\n",
    "2. **Check and validate** downloaded files \n",
    "3. **Convert custom spatial data** to GeoJSON format\n",
    "4. **Generate PMTiles** using optimized tippecanoe settings\n",
    "5. **Create TileJSON metadata** for web mapping integration\n",
    "6. **Validate and test** individual processing steps\n",
    "\n",
    "## Key Features\n",
    "- **Modular design** - Each step can be run independently\n",
    "- **Flexible configuration** - Easy to customize for different areas and data types\n",
    "- **Interactive development** - Run steps individually for debugging\n",
    "- **Performance optimized** - Appropriate settings for different geometry types\n",
    "- **Production ready** - Robust error handling and validation\n",
    "\n",
    "## Output Files\n",
    "Each step generates specific outputs that can be directly used:\n",
    "- **GeoJSON/GeoJSONSeq files** for further processing or analysis\n",
    "- **PMTiles files** for efficient web mapping\n",
    "- **TileJSON metadata** for MapLibre GL JS integration\n",
    "\n",
    "## Usage Patterns\n",
    "- **Development**: Run steps individually for testing and debugging\n",
    "- **Production**: Execute all steps in sequence for automated processing\n",
    "- **Customization**: Modify CONFIG settings and re-run specific steps\n",
    "- **Integration**: Use generated files with web mapping applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
